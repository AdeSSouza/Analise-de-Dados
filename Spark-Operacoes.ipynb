{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 7</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** Atenção: *********** \n",
    "Utilize Java JDK 11 e Apache Spark 2.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Caso receba mensagem de erro \"name 'sc' is not defined\", interrompa o pyspark e apague o diretório metastore_db no mesmo diretório onde está este Jupyter notebook*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acesse http://localhost:4040 sempre que quiser acompanhar a execução dos jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista em Python\n",
    "lista1 = [124, 901, 652, 102, 397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lista1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dados de uma coleção\n",
    "lstRDD = sc.parallelize(lista1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lstRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando um arquivo e criando um RDD. \n",
    "autoDataRDD = sc.textFile(\"data/carros.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(autoDataRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operação de Ação. \n",
    "autoDataRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDataRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada ação gera um novo processo de computação dos dados. \n",
    "# Mas podemos persistir os dados em cache para que ele possa ser usado por outras ações, sem a necessidade \n",
    "# de nova computação.\n",
    "autoDataRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in autoDataRDD.collect():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map() e criação de um novo RDD - Transformação - Lazy Evaluation\n",
    "tsvData = autoDataRDD.map(lambda x : x.replace(\",\",\"\\t\"))\n",
    "tsvData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDataRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter() e criação de um novo RDD - Transformação - Lazy Evaluation\n",
    "toyotaData = autoDataRDD.filter(lambda x: \"toyota\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ação\n",
    "toyotaData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ação\n",
    "toyotaData.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pode salvar o conjunto de dados, o RDD. \n",
    "# Nesse caso, o Spark solicita os dados ao processo Master e então gera um arquivo de saída.\n",
    "savedRDD = open(\"data/carros_v2.csv\",\"w\")\n",
    "savedRDD.write(\"\\n\".join(autoDataRDD.collect()))\n",
    "savedRDD.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set operations\n",
    "palavras1 = sc.parallelize([\"Big Data\",\"Data Science\",\"Analytics\",\"Visualization\"])\n",
    "palavras2 = sc.parallelize([\"Big Data\",\"R\",\"Python\",\"Scala\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# União\n",
    "for unions in palavras1.union(palavras2).distinct().collect():\n",
    "    print(unions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interseção\n",
    "for intersects in palavras1.intersection(palavras2).collect():\n",
    "    print(intersects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd01 = sc.parallelize(range(1,10))\n",
    "rdd02 = sc.parallelize(range(10,21))\n",
    "rdd01.union(rdd02).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd01 = sc.parallelize(range(1,10))\n",
    "rdd02 = sc.parallelize(range(5,15))\n",
    "rdd01.intersection(rdd02).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left/Right Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = sc.parallelize((\"banana\", \"uva\", \"laranja\")).map(lambda a: (a, 1))\n",
    "names2 = sc.parallelize((\"laranja\", \"abacaxi\", \"manga\")).map(lambda a: (a, 1))\n",
    "names1.join(names2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1.leftOuterJoin(names2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1.rightOuterJoin(names2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distinct\n",
    "lista1 = [124, 901, 652, 102, 397, 124, 901, 652]\n",
    "lstRDD = sc.parallelize(lista1)\n",
    "for numbData in lstRDD.distinct().collect():\n",
    "    print(numbData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Transformação e Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD Original\n",
    "autoDataRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação e Limpeza\n",
    "def LimpaRDD(autoStr) :\n",
    "    \n",
    "    # Verifica a indexação \n",
    "    if isinstance(autoStr, int) :\n",
    "        return autoStr\n",
    "    \n",
    "    # Separa cada índice pela vírgula (separador de colunas)\n",
    "    attList = autoStr.split(\",\")\n",
    "    \n",
    "    # Converte o número de portas para um num\n",
    "    if attList[3] == \"two\" :\n",
    "        attList[3] = \"2\"\n",
    "    elif attList[3] == \"four\":\n",
    "        attList[3] = \"4\"\n",
    "    \n",
    "    # Convert o modelo do carro para uppercase\n",
    "    attList[5] = attList[4].upper()\n",
    "    return \",\".join(attList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação\n",
    "RDD_limpo = autoDataRDD.map(LimpaRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RDD_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ação\n",
    "RDD_limpo.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce() - soma de valores\n",
    "lista2 = [124, 901, 652, 102, 397, 124, 901, 652]\n",
    "lstRDD = sc.parallelize(lista2)\n",
    "lstRDD.collect()\n",
    "lstRDD.reduce(lambda x,y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrando a linha com menor número de caracteres\n",
    "autoDataRDD.reduce(lambda x,y: x if len(x) < len(y) else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função para redução\n",
    "def getMPG(autoStr) :\n",
    "    \n",
    "    if isinstance(autoStr, int) :\n",
    "        return autoStr\n",
    "    \n",
    "    attList = autoStr.split(\",\")\n",
    "    \n",
    "    if attList[9].isdigit() :\n",
    "        return int(attList[9])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrando a média de MPG para todos os carros\n",
    "media_mpg = round(autoDataRDD.reduce(lambda x,y : getMPG(x) + getMPG(y)) / (autoDataRDD.count() -1), 2)\n",
    "print(media_mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sc.parallelize((\"Flamengo\", \"Vasco\", \"Botafogo\", \"Fluminense\", \"Palmeiras\", \"Bahia\"))\n",
    "times.takeSample(True, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sc.parallelize((\"Flamengo\", \"Vasco\", \"Botafogo\", \"Fluminense\", \"Palmeiras\", \"Bahia\", \"Bahia\", \"Flamengo\"))\n",
    "times.map(lambda k: (k,1)).countByKey().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDataRDD.saveAsTextFile(\"data/autoDataRDD.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
